---
title: References
---

# References

  * <a name="B77"></a>[B77] Bandura, A. (1977). Self-efficacy: Toward a unifying theory of behavioral change. Psychological Review, 84(2), 191-215.
  * <a name="BD12"></a> [BD12] Bishop-Clark, C., Bietz-Uhler, B., Engaging in the Scholarship of Teaching and Learning, Stylus, 2012.
  * <a name="CC18"></a>[CC18] Creswell & Creswell, Research Design, Sage, Los Angeles, 2018.
  * <a name="DT15"></a> [DT15] B. Dorn and A. E. Tew. Empirical Validation and Application of the Computing Attitudes Survey. Computer Science Education, 25(1):1-36, 2015 -- http://dx.doi.org/10.1080/08993408.2015.1014142
  * <a name="DT13"></a> [DT13] B. Dorn and A. E. Tew. Becoming Experts: Measuring Attitude Development in Introductory Computer Science. InSIGCSE '13: Proceedings of the 44th SIGCSE Technical Symposium on Computer Science Education, pages 183-188, 2013. [PDF - via ACM DL]
  * <a name="GXH19"></a> [[GXH19]](https://doi.org/10.1109/TLT.2019.2911832) N. Gitinabard, Y. Xu, S. Heckman, T. Barnes and C. F. Lynch, "How Widely Can Prediction Models Be Generalized? Performance Prediction in Blended Courses," in IEEE Transactions on Learning Technologies, vol. 12, no. 2, pp. 184-197, 1 April-June 2019, doi: 10.1109/TLT.2019.2911832.
  * <a name="MDZ18"></a>[[MDZ18]](https://csedresearch.org/reporting-activities/) Monica M. McGill, Adrienne Decker, and Zachary Abbott. 2018. Improving Research and Experience Reports of Pre-College Computing Activities: A Gap Analysis. In Proceedings of the 2018 ACM SIGCSE Technical Symposium on Computer Science Education (SIGCSE ’18). ACM, New York, NY, USA
  * <a name="MX19ReliabilityValidity"></a> [[MX19ReliabilityValidity]](https://csedresearch.org/measuring-reliability-and-validity/) McGill, Monica M. and Xavier, Jeffrey. 2019. Measuring Reliability and Validity. Retrieved from https://csedresearch.org
  * <a name="MX19Instruments"></a>[[MX19Instruments]](https://csedresearch.org/choosing-an-evaluation-instrument/) Xavier, Jeffrey and McGill, Monica M. 2019. Choosing an Evaluation Instrument. csedresearch.org. Retrieved from https://csedresearch.org/choosing-an-evaluation-instrument
  * <a name="RW98"></a> [RW98] Ramalingam V, Wiedenbeck S. Development and Validation of Scores on a Computer Programming Self-Efficacy Scale and Group Analyses of Novice Programmer Self-Efficacy. Journal of Educational Computing Research. 1998;19(4):367-381. doi:10.2190/C670-Y3C8-LTJ1-CT3P
  * <a name="SG14"></a> [SG14] M. J. Scott and G. Ghinea, “Measuring Enrichment: The Assembly and Validation of an Instrument to Assess Student Self-Beliefs in CS1,” ICER 14, p. 123-130.
  * <a name="T10"></a> [T10] Tew, A.E. 2010. Assessing Fundamental Introductory Computing Concept Knowledge in a Language Independent Manner Assessing Fundamental Introductory Computing Concept Knowledge. Doctoral Thesis. Georgia Institute of Technology.
  * <a name="TDS12"></a> [TDS12] A. Elliott Tew, B. Dorn, and O. Schneider. Toward a Validated Computing Attitudes Survey. In ICER'12: Proceedings of the 8th International Computing Education Research Conference, pages 135-142, 2012. [PDF - via ACM DL]
  * <a name="TD13"></a>[TD13] A. E. Tew and B. Dorn The Case for Validated Tools in Computing Education Research. IEEE Computer (Special Issue on Computing Education), 46(9):60-66, 2013.
  
  